{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course2025-stats1/blob/main/topic_analysis_with_PLSI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeA8pNfaQCb8"
      },
      "source": [
        "# PLSI (PLSA) によるトピック分析\n",
        "* PLSI = probabilistic latent semantic indexing\n",
        "* PLSA = probabilistic latent semantic analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVfmr_VxdCV7"
      },
      "source": [
        "## データセット"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJc4cZOYL6mf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wG-Cxlc69Lhh"
      },
      "source": [
        "* 文書数を減らすために、4つのカテゴリの文書だけを使う。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Asj05LoSQLJH"
      },
      "outputs": [],
      "source": [
        "categories = ['rec.motorcycles', 'rec.sport.baseball', 'comp.graphics', 'sci.med']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaK4LDg7MCMK"
      },
      "outputs": [],
      "source": [
        "twenty_train = fetch_20newsgroups(subset='train', categories=categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eC7X93UdMi0b"
      },
      "outputs": [],
      "source": [
        "twenty_train.target_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sku_CR-CMZdA"
      },
      "outputs": [],
      "source": [
        "len(twenty_train.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sET1SYfbMUIO"
      },
      "outputs": [],
      "source": [
        "count_vect = CountVectorizer(min_df=20, max_df=0.1, stop_words=\"english\")\n",
        "X_train_counts = count_vect.fit_transform(twenty_train.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3WcjnwhMsYq"
      },
      "outputs": [],
      "source": [
        "X_train_counts.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AImcNwGhRsXc"
      },
      "outputs": [],
      "source": [
        "type(X_train_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdPycQRQRt-m"
      },
      "outputs": [],
      "source": [
        "X_train_counts = X_train_counts.toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNH24vMzQYHG"
      },
      "source": [
        "* 単語のインデックス"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtHmlQDHMuqh"
      },
      "outputs": [],
      "source": [
        "count_vect.vocabulary_.get('apple')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_xyVnc1VLJv"
      },
      "outputs": [],
      "source": [
        "count_vect.get_feature_names_out()[224]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnTMiHA5QcAA"
      },
      "source": [
        "* 除去されたストップワード"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qy3LJtiWNhHv"
      },
      "outputs": [],
      "source": [
        "print(count_vect.get_stop_words())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cS16QxhdAcj"
      },
      "source": [
        "## モデルの設定"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylRmJVYg5YJ5"
      },
      "source": [
        "* $D$: 文書数\n",
        "* $W$: 語彙数\n",
        "* $K$: トピック数（これは自分で決める）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYncaBLEN4cd"
      },
      "outputs": [],
      "source": [
        "n_docs, n_words = X_train_counts.shape\n",
        "n_topics = 10\n",
        "print(f\"{n_docs} documents, {n_words} different words, and {n_topics} topics\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cM7uoh5X5jCK"
      },
      "source": [
        "## モデルのパラメータ\n",
        "* `q`の形は[D, W, K]\n",
        " * $q_{d,w,k}$は、$d$番目の文書で$w$番目の単語が、$K$個のトピックのうち$k$番目のトピックを表現するために使われる確率。\n",
        "* `theta`の形は[D, K]\n",
        " * $\\theta_{d,k}$は、$d$番目の文書で、$K$個のトピックのうち$k$番目のトピックを表現するためにいずれかの単語が使われる確率。\n",
        "* `phi`の形は、ここでの実装上は、[W, K]\n",
        " * 授業資料では、$\\phi_{k, w}$と添え字が付けられていたので、ここでは転置してある。\n",
        " * $\\phi_{k,w}$は、$k$番目のトピックを表現するために、$W$種類ある単語のうち$w$番目の単語が使われる確率。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2RUGakedEzP"
      },
      "source": [
        "## M step\n",
        "* モデルパラメータを更新する。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bus8FvsSOr4U"
      },
      "outputs": [],
      "source": [
        "def m_step(counts, q):\n",
        "    pseudo_counts = counts[:, :, None] * q\n",
        "    theta = pseudo_counts.sum(1)\n",
        "    theta = theta / theta.sum(-1, keepdims=True)\n",
        "    phi = pseudo_counts.sum(0)\n",
        "    phi = phi / phi.sum(0, keepdims=True)\n",
        "    return theta, phi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f51SOYgJdF4j"
      },
      "source": [
        "## E step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmN7IzIJ7AKA"
      },
      "source": [
        "* responsibilityを更新する。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zI3jsA8iPnwa"
      },
      "outputs": [],
      "source": [
        "def e_step(theta, phi):\n",
        "    q = theta[:, None, :] * phi[None, :, :]\n",
        "    q = q / q.sum(-1, keepdims=True)\n",
        "    return q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsugV3xsdG_p"
      },
      "source": [
        "## lower boundの計算\n",
        "* EMアルゴリズムがlower boundを大きくしていっているかチェックするため。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZL2Yg3KR9F5"
      },
      "outputs": [],
      "source": [
        "def lower_bound(counts, q, theta, phi):\n",
        "    pseudo_counts = counts[:, :, None] * q\n",
        "    lb = (pseudo_counts * np.log(theta[:, None, :] + 1e-16)).sum()\n",
        "    lb += (pseudo_counts * np.log(phi[None, :, :] + 1e-16)).sum()\n",
        "    lb -= (pseudo_counts * np.log(q + 1e-16)).sum()\n",
        "    return lb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-E0SLaFdI3f"
      },
      "source": [
        "## 初期化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jGZe7tHSBDA"
      },
      "outputs": [],
      "source": [
        "q = np.random.randn(n_docs, n_words, n_topics)\n",
        "q = np.exp(q) / np.exp(q).sum(-1, keepdims=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZTnw5jRdKQ2"
      },
      "source": [
        "## EMアルゴリズムの実行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LY6lFkjpSFPn"
      },
      "outputs": [],
      "source": [
        "for i in range(50):\n",
        "  theta, phi = m_step(X_train_counts, q)\n",
        "  q = e_step(theta, phi)\n",
        "  lb = lower_bound(X_train_counts, q, theta, phi)\n",
        "  print(f\"iter {i+1} | lower bound {lb:.4e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JxPSP0hdNWB"
      },
      "source": [
        "## トピック語の表示\n",
        "* 各$k$について、$\\phi_{k,w}$が大きい順に単語を拾う。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FE-5qAySG4P"
      },
      "outputs": [],
      "source": [
        "topic_words = np.argsort(- phi, axis=0)\n",
        "for k in range(n_topics):\n",
        "  print(k, end=' : ')\n",
        "  for i in range(20):\n",
        "    print(count_vect.get_feature_names_out()[topic_words[i, k]], end=', ')\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5_rgnjl7fi5"
      },
      "source": [
        "# 自由課題\n",
        "* ここでは、$q_{d,w,k}$を（文書数）✖️（語彙数）✖️（トピック数）という巨大な配列として実装した。\n",
        "* しかし、文書数や語彙数が増えると、このサイズの配列をメインメモリ上に用意することはできなくなる。\n",
        "* $q_{d,w,k}$をどのように実装すれば、この問題を回避できるか？"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gsb_mBwWHqR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "python",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}